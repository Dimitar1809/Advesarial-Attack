{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms shape: (30000, 227, 169)\n",
      "Targets shape: (30000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "import numpy as np\n",
    "# Path to the saved .npy files\n",
    "spectrograms_file = \"dataSpectogram/spectrograms.npy\"\n",
    "targets_file = \"dataSpectogram/targets.npy\"\n",
    "\n",
    "# Load the spectrograms and targets\n",
    "spectrograms = np.load(spectrograms_file)\n",
    "targets = np.load(targets_file)\n",
    "\n",
    "# Verify the data\n",
    "print(f\"Spectrograms shape: {spectrograms.shape}\")  # Should be (num_samples, 227, fixed_time_dim)\n",
    "print(f\"Targets shape: {targets.shape}\")  # Should be (num_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "indices = np.arange(len(spectrograms))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "spectrograms = spectrograms[indices]\n",
    "targets = targets[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable data: 18000 samples\n",
      "Adversarial data: 12000 samples\n",
      "Training data: 14400 samples\n",
      "Testing data: 3600 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Use only 60% of the data\n",
    "num_samples = len(spectrograms)\n",
    "num_training_samples = int(0.6 * num_samples)\n",
    "\n",
    "# Split data into 60% usable data and 40% for adversarial attack\n",
    "usable_spectrograms = spectrograms[:num_training_samples]\n",
    "usable_targets = targets[:num_training_samples]\n",
    "# Expand dimensions to match AlexNet input format (add a channel dimension)\n",
    "usable_spectrograms = usable_spectrograms[..., np.newaxis]  # Shape: (num_samples, 227, 169, 1)\n",
    "\n",
    "adversarial_spectrograms = spectrograms[num_training_samples:]\n",
    "adversarial_targets = targets[num_training_samples:]\n",
    "\n",
    "# Verify splits\n",
    "print(f\"Usable data: {len(usable_spectrograms)} samples\")\n",
    "print(f\"Adversarial data: {len(adversarial_spectrograms)} samples\")\n",
    "\n",
    "# Further split the 60% usable data into training and testing sets\n",
    "# Convert targets to one-hot encoding\n",
    "num_classes = len(np.unique(targets))\n",
    "targets_one_hot = to_categorical(usable_targets, num_classes=num_classes)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(usable_spectrograms, targets_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data: {len(X_train)} samples\")\n",
    "print(f\"Testing data: {len(X_val)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AlexNet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " data (InputLayer)           [(None, 227, 169, 1)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 55, 40, 96)        11712     \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 55, 40, 96)        0         \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 27, 19, 96)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 27, 19, 256)       307456    \n",
      "                                                                 \n",
      " relu2 (ReLU)                (None, 27, 19, 256)       0         \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 13, 9, 256)        0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 13, 9, 384)        885120    \n",
      "                                                                 \n",
      " relu3 (ReLU)                (None, 13, 9, 384)        0         \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 13, 9, 384)        663936    \n",
      "                                                                 \n",
      " relu4 (ReLU)                (None, 13, 9, 384)        0         \n",
      "                                                                 \n",
      " conv5 (Conv2D)              (None, 13, 9, 256)        442624    \n",
      "                                                                 \n",
      " relu5 (ReLU)                (None, 13, 9, 256)        0         \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 6, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6144)              0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 1024)              6292480   \n",
      "                                                                 \n",
      " relu6 (ReLU)                (None, 1024)              0         \n",
      "                                                                 \n",
      " drop6 (Dropout)             (None, 1024)              0         \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 1024)              1049600   \n",
      "                                                                 \n",
      " relu7 (ReLU)                (None, 1024)              0         \n",
      "                                                                 \n",
      " drop7 (Dropout)             (None, 1024)              0         \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 10)                10250     \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,663,178\n",
      "Trainable params: 9,663,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load fixed model\n",
    "model = tf.keras.models.load_model(\"alexnet_spectrogram_model.h5\")\n",
    "\n",
    "# Verify the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 34s 21ms/step - loss: 0.0814 - accuracy: 0.9781\n",
      "Validation Loss: 0.0814\n",
      "Validation Accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation data to see how well it predicts\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def pgd_attack(model, spectrogram, label, epsilon=0.1, alpha=0.01, num_iter=40):\n",
    "\n",
    "    # Clone the spectrogram to avoid modifying the original input\n",
    "    perturbed_spectrogram = tf.cast(tf.identity(spectrogram), tf.float32)  # Ensure it's float32\n",
    "\n",
    "    # Add random initialization within the epsilon ball\n",
    "    perturbed_spectrogram += tf.random.uniform(perturbed_spectrogram.shape, minval=-epsilon, maxval=epsilon, dtype=tf.float32)\n",
    "    perturbed_spectrogram = tf.clip_by_value(perturbed_spectrogram, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "    # Perform iterative attack\n",
    "    for _ in range(num_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(perturbed_spectrogram)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(perturbed_spectrogram)\n",
    "\n",
    "            # Compute loss (cross-entropy)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(label, predictions)\n",
    "\n",
    "        # Compute gradients of loss with respect to input\n",
    "        gradient = tape.gradient(loss, perturbed_spectrogram)\n",
    "        signed_grad = tf.sign(gradient)\n",
    "\n",
    "        # Update the perturbed spectrogram\n",
    "        perturbed_spectrogram += alpha * signed_grad\n",
    "\n",
    "        # Project back to the epsilon-ball and ensure valid pixel range\n",
    "        perturbation = tf.clip_by_value(perturbed_spectrogram - spectrogram, -epsilon, epsilon)\n",
    "        perturbed_spectrogram = tf.clip_by_value(spectrogram + perturbation, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "    return perturbed_spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for adversarial example: 7\n",
      "True class: 4\n"
     ]
    }
   ],
   "source": [
    "# Example spectrogram and label\n",
    "index = 150  # Choose an index from the validation set\n",
    "sample_spectrogram = X_val[index]  \n",
    "label = y_val[index]  \n",
    "\n",
    "# Convert to TensorFlow tensors\n",
    "sample_spectrogram = tf.convert_to_tensor(sample_spectrogram, dtype=tf.float32)\n",
    "label = tf.convert_to_tensor(label, dtype=tf.float32)  # Ensure label is float32\n",
    "\n",
    "# Add batch and channel dimensions to spectrogram\n",
    "sample_spectrogram = tf.expand_dims(sample_spectrogram, axis=0)  # Add batch dimension\n",
    "sample_spectrogram = tf.expand_dims(sample_spectrogram, axis=-1)  # Add channel dimension\n",
    "label = tf.expand_dims(label, axis=0)  # Add batch dimension to match predictions\n",
    "\n",
    "\n",
    "# Perform PGD attack\n",
    "adversarial_example = pgd_attack(model, sample_spectrogram, label, epsilon=0.1, alpha=0.01, num_iter=40)\n",
    "\n",
    "# Get predictions for the adversarial example\n",
    "predictions = model(adversarial_example)\n",
    "predicted_class = tf.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Predicted class for adversarial example:\", predicted_class.numpy()[0])\n",
    "print('True class:', np.argmax(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of normal model under PGD Attack: 9.50%\n"
     ]
    }
   ],
   "source": [
    "#check how well the model is doing on validation data with adversarial attack\n",
    "def evaluate_pgd_attack(model, X_val, y_val, epsilon=0.1, alpha=0.01, num_iter=40):\n",
    "    \n",
    "    total_samples = X_val.shape[0]\n",
    "    total_samples = 1000  \n",
    "    correct_predictions = 0\n",
    "\n",
    "    for i in range(total_samples):\n",
    "        # Get the i-th spectrogram and label\n",
    "        sample_spectrogram = X_val[i]\n",
    "        label = y_val[i]\n",
    "\n",
    "        # Convert to TensorFlow tensors\n",
    "        sample_spectrogram = tf.convert_to_tensor(sample_spectrogram, dtype=tf.float32)\n",
    "        label = tf.convert_to_tensor(label, dtype=tf.float32)\n",
    "\n",
    "        # Add batch and channel dimensions to spectrogram\n",
    "        sample_spectrogram = tf.expand_dims(sample_spectrogram, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Add batch dimension to label\n",
    "        label = tf.expand_dims(label, axis=0)\n",
    "\n",
    "        # Generate adversarial example using PGD\n",
    "        adversarial_example = pgd_attack(\n",
    "            model, sample_spectrogram, label,\n",
    "            epsilon=epsilon, alpha=alpha, num_iter=num_iter\n",
    "        )\n",
    "\n",
    "        # Make a prediction on the adversarial example\n",
    "        predictions = model(adversarial_example)\n",
    "        predicted_class = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "        true_class = tf.argmax(label, axis=1).numpy()[0]\n",
    "\n",
    "        # Check if the prediction matches the true label\n",
    "        if predicted_class == true_class:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    # Calculate adversarial accuracy\n",
    "    adversarial_accuracy = correct_predictions / total_samples\n",
    "    return adversarial_accuracy\n",
    "\n",
    "\n",
    "# Evaluate model under PGD attack\n",
    "adversarial_accuracy = evaluate_pgd_attack(model, X_val, y_val, epsilon=0.1, alpha=0.01, num_iter=40)\n",
    "\n",
    "print(f\"Accuracy of normal model under PGD Attack: {adversarial_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarial_examples(model, x_batch, y_batch, epsilon):\n",
    "    x_batch = tf.convert_to_tensor(x_batch, dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x_batch)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(x_batch)\n",
    "\n",
    "        # Ensure labels match batch size\n",
    "        y_batch = tf.reshape(y_batch, (tf.shape(x_batch)[0],))  # Dynamically match batch size\n",
    "\n",
    "        # Compute loss\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions)\n",
    "\n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(loss, x_batch)\n",
    "\n",
    "    # Generate adversarial example\n",
    "    adv_x = x_batch + epsilon * tf.sign(gradients)\n",
    "\n",
    "    # Clip values to be within valid range\n",
    "    return tf.clip_by_value(adv_x, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training(model, x_train, y_train, x_val, y_val, epochs=5, batch_size=32, epsilon=0.1):\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for i in range(0, len(x_train), batch_size):\n",
    "            x_batch = x_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "            # Convert to tensors\n",
    "            x_batch = tf.convert_to_tensor(x_batch, dtype=tf.float32)\n",
    "            y_batch = tf.convert_to_tensor(y_batch, dtype=tf.float32)\n",
    "\n",
    "            # Convert one-hot labels to class indices\n",
    "            if len(y_batch.shape) > 1 and y_batch.shape[1] > 1:\n",
    "                y_batch = tf.argmax(y_batch, axis=1)  # Convert to class indices\n",
    "\n",
    "            y_batch = tf.cast(y_batch, tf.int64)\n",
    "\n",
    "            # Generate adversarial examples\n",
    "            adv_x_batch = generate_adversarial_examples(model, x_batch, y_batch, epsilon)\n",
    "\n",
    "            # Train the model on adversarial examples\n",
    "            model.train_on_batch(adv_x_batch, y_batch)\n",
    "\n",
    "    #Fix: Ensure `y_val` is an int64 tensor (Remove unnecessary conversion to float32)\n",
    "    y_val = tf.convert_to_tensor(y_val, dtype=tf.int64)\n",
    "\n",
    "    if len(y_val.shape) > 1 and y_val.shape[1] > 1:\n",
    "        y_val = tf.argmax(y_val, axis=1)  # Convert one-hot to class indices\n",
    "\n",
    "    # Evaluate model on validation set\n",
    "    val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n",
      "Validation Loss: 96.1315, Accuracy: 0.1006\n"
     ]
    }
   ],
   "source": [
    "# Adversarial Training\n",
    "adversarial_training(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of advesarially trained model under PGD Attack: 6.70%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model under PGD attack\n",
    "adversarial_accuracy = evaluate_pgd_attack(model, X_val, y_val, epsilon=0.1, alpha=0.01, num_iter=40)\n",
    "print(f\"Accuracy of advesarially trained model under PGD Attack: {adversarial_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
