{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, ReLU, MaxPooling2D, Flatten,\n",
    "    Dense, Dropout, Softmax\n",
    ")\n",
    "\n",
    "def create_alexnet(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape, name=\"data\")\n",
    "\n",
    "    # Conv1 + ReLU + Pool1\n",
    "    x = Conv2D(96, kernel_size=11, strides=4, padding=\"valid\", activation=None,\n",
    "               kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", name=\"conv1\")(input_layer)\n",
    "    x = ReLU(name=\"relu1\")(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, name=\"pool1\")(x)\n",
    "\n",
    "    # Conv2 + ReLU + Pool2\n",
    "    x = Conv2D(256, kernel_size=5, strides=1, padding=\"same\", activation=None, groups=2,\n",
    "               kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", name=\"conv2\")(x)\n",
    "    x = ReLU(name=\"relu2\")(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, name=\"pool2\")(x)\n",
    "\n",
    "    # Conv3 + ReLU\n",
    "    x = Conv2D(384, kernel_size=3, strides=1, padding=\"same\",\n",
    "               kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", name=\"conv3\")(x)\n",
    "    x = ReLU(name=\"relu3\")(x)\n",
    "\n",
    "    # Conv4 + ReLU\n",
    "    x = Conv2D(384, kernel_size=3, strides=1, padding=\"same\", groups=2,\n",
    "               kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", name=\"conv4\")(x)\n",
    "    x = ReLU(name=\"relu4\")(x)\n",
    "\n",
    "    # Conv5 + ReLU + Pool5\n",
    "    x = Conv2D(256, kernel_size=3, strides=1, padding=\"same\", groups=2,\n",
    "               kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", name=\"conv5\")(x)\n",
    "    x = ReLU(name=\"relu5\")(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, name=\"pool5\")(x)\n",
    "\n",
    "    # Flatten for Fully Connected Layers\n",
    "    x = Flatten(name=\"flatten\")(x)\n",
    "\n",
    "    # FC6 + ReLU + Dropout\n",
    "    x = Dense(1024, activation=None, kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", name=\"fc6\")(x)\n",
    "    x = ReLU(name=\"relu6\")(x)\n",
    "    x = Dropout(rate=0.5, name=\"drop6\")(x)\n",
    "\n",
    "    # FC7 + ReLU + Dropout\n",
    "    x = Dense(1024, activation=None, kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", name=\"fc7\")(x)\n",
    "    x = ReLU(name=\"relu7\")(x)\n",
    "    x = Dropout(rate=0.5, name=\"drop7\")(x)\n",
    "\n",
    "    # FC8 + Softmax for Final Output\n",
    "    x = Dense(num_classes, activation=None, kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", name=\"fc8\")(x)\n",
    "    output = Softmax(name=\"softmax\")(x)\n",
    "\n",
    "    # Create Model\n",
    "    model = Model(inputs=input_layer, outputs=output, name=\"AlexNet\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms shape: (30000, 227, 169)\n",
      "Targets shape: (30000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Path to the saved .npy files\n",
    "spectrograms_file = \"C:/Users/mitak/OneDrive - University of Twente/Documents/UTwente/Master Robotics/Module2/Deep Learning/Advesarial-Attack/dataSpectogram/spectrograms.npy\"\n",
    "targets_file = \"C:/Users/mitak/OneDrive - University of Twente/Documents/UTwente/Master Robotics/Module2/Deep Learning/Advesarial-Attack/dataSpectogram/targets.npy\"\n",
    "\n",
    "# Load the spectrograms and targets\n",
    "spectrograms = np.load(spectrograms_file)\n",
    "targets = np.load(targets_file)\n",
    "\n",
    "# Verify the data\n",
    "print(f\"Spectrograms shape: {spectrograms.shape}\")  # Should be (num_samples, 227, fixed_time_dim)\n",
    "print(f\"Targets shape: {targets.shape}\")  # Should be (num_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "indices = np.arange(len(spectrograms))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "spectrograms = spectrograms[indices]\n",
    "targets = targets[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable data: 18000 samples\n",
      "Adversarial data: 12000 samples\n",
      "Training data: 14400 samples\n",
      "Testing data: 3600 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Use only 60% of the data\n",
    "num_samples = len(spectrograms)\n",
    "num_training_samples = int(0.6 * num_samples)\n",
    "\n",
    "# Split data into 60% usable data and 40% for adversarial attack\n",
    "usable_spectrograms = spectrograms[:num_training_samples]\n",
    "usable_targets = targets[:num_training_samples]\n",
    "# Expand dimensions to match AlexNet input format (add a channel dimension)\n",
    "usable_spectrograms = usable_spectrograms[..., np.newaxis]  # Shape: (num_samples, 227, 169, 1)\n",
    "\n",
    "adversarial_spectrograms = spectrograms[num_training_samples:]\n",
    "adversarial_targets = targets[num_training_samples:]\n",
    "\n",
    "# Verify splits\n",
    "print(f\"Usable data: {len(usable_spectrograms)} samples\")\n",
    "print(f\"Adversarial data: {len(adversarial_spectrograms)} samples\")\n",
    "\n",
    "# Further split the 60% usable data into training and testing sets\n",
    "# Convert targets to one-hot encoding\n",
    "num_classes = len(np.unique(targets))\n",
    "targets_one_hot = to_categorical(usable_targets, num_classes=num_classes)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(usable_spectrograms, targets_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data: {len(X_train)} samples\")\n",
    "print(f\"Testing data: {len(X_val)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AlexNet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " data (InputLayer)           [(None, 227, 169, 1)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 55, 40, 96)        11712     \n",
      "                                                                 \n",
      " relu1 (ReLU)                (None, 55, 40, 96)        0         \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 27, 19, 96)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 27, 19, 256)       307456    \n",
      "                                                                 \n",
      " relu2 (ReLU)                (None, 27, 19, 256)       0         \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 13, 9, 256)        0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 13, 9, 384)        885120    \n",
      "                                                                 \n",
      " relu3 (ReLU)                (None, 13, 9, 384)        0         \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 13, 9, 384)        663936    \n",
      "                                                                 \n",
      " relu4 (ReLU)                (None, 13, 9, 384)        0         \n",
      "                                                                 \n",
      " conv5 (Conv2D)              (None, 13, 9, 256)        442624    \n",
      "                                                                 \n",
      " relu5 (ReLU)                (None, 13, 9, 256)        0         \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 6, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6144)              0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 1024)              6292480   \n",
      "                                                                 \n",
      " relu6 (ReLU)                (None, 1024)              0         \n",
      "                                                                 \n",
      " drop6 (Dropout)             (None, 1024)              0         \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 1024)              1049600   \n",
      "                                                                 \n",
      " relu7 (ReLU)                (None, 1024)              0         \n",
      "                                                                 \n",
      " drop7 (Dropout)             (None, 1024)              0         \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 10)                10250     \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,663,178\n",
      "Trainable params: 9,663,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (227, 169, 1)  # Include the channel dimension\n",
    "model = create_alexnet(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_built_with_cuda())  # Should return True\n",
    "print(tf.config.list_physical_devices('GPU'))  # Should list at least one GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust batch size based on available memory\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Adjust number of epochs as needed\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Display progress during training\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mitak\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mitak\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=32,  # Adjust batch size based on available memory\n",
    "    epochs=20,      # Adjust number of epochs as needed\n",
    "    verbose=1       # Display progress during training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import istft\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "#Check the model predictions to verify that the predictions are correct\n",
    "# Function to reconstruct the audio from the spectrogram\n",
    "def spectrogram_to_audio(spectrogram, sample_rate=8000, nperseg=None, noverlap=None):\n",
    "    \"\"\"\n",
    "    Converts a spectrogram back to a time-domain audio signal.\n",
    "    \"\"\"\n",
    "    import librosa\n",
    "    \n",
    "    # Convert the decibel spectrogram back to amplitude\n",
    "    spectrogram_amp = librosa.db_to_amplitude(spectrogram, ref=1.0)\n",
    "\n",
    "    # Infer nperseg and noverlap if not provided\n",
    "    if nperseg is None or noverlap is None:\n",
    "        nperseg = spectrogram.shape[0]  # Use the number of frequency bins as nperseg\n",
    "        noverlap = nperseg - (spectrogram.shape[1] // 2)  # Approximation for overlap\n",
    "\n",
    "    # Reconstruct the signal using ISTFT\n",
    "    _, audio = istft(\n",
    "        spectrogram_amp,\n",
    "        fs=sample_rate,\n",
    "        nperseg=nperseg,\n",
    "        noverlap=noverlap,\n",
    "        window=\"hann\"\n",
    "    )\n",
    "    return audio\n",
    "\n",
    "# Select a random spectrogram from the validation set\n",
    "index = 200  # Replace with any index you want to check\n",
    "sample_spectrogram = X_val[index]\n",
    "true_target = np.argmax(y_val[index])  # Get the actual label\n",
    "\n",
    "# Ensure spectrogram is 2D by squeezing the channel dimension\n",
    "sample_spectrogram_2d = sample_spectrogram.squeeze()  # Shape: (227, 169)\n",
    "\n",
    "# Predict the target using the trained model\n",
    "predicted_target = np.argmax(model.predict(sample_spectrogram[np.newaxis, ...]))\n",
    "\n",
    "# Display the predicted and true target\n",
    "print(f\"True Target: {true_target}\")\n",
    "print(f\"Predicted Target: {predicted_target}\")\n",
    "\n",
    "# Convert the spectrogram back to audio\n",
    "reconstructed_audio = spectrogram_to_audio(sample_spectrogram_2d)\n",
    "\n",
    "# Play the audio in the notebook\n",
    "Audio(reconstructed_audio, rate=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save(\"alexnet_spectrogram_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
